import os, requests
from bs4 import BeautifulSoup
import time

def banner():
    os.system("clear")
    print("""
\033[1;32m
â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— 
â•šâ•â•â–ˆâ–ˆâ•”â•â•â•â–ˆâ–ˆâ•”â•â•â•â•â•â–ˆâ–ˆâ•”â•â•â•â•â•â•šâ•â•â–ˆâ–ˆâ•”â•â•â•â–ˆâ–ˆâ•”â•â•â•â•â•â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—
   â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—   â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•
   â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•”â•â•â•  â•šâ•â•â•â•â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•”â•â•â•  â–ˆâ–ˆâ•”â•â•â•â• 
   â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘     
   â•šâ•â•   â•šâ•â•â•â•â•â•â•â•šâ•â•â•â•â•â•â•   â•šâ•â•   â•šâ•â•â•â•â•â•â•â•šâ•â•     
\033[1;37m
 ğŸŒ AF-BypassProxy | Dev: Ali Hamza AF
 ğŸ›¡ï¸ Powered By: AF Cyber Force | Termux Special
=================================================
""")


def fetch_proxies():
    print("\n[~] Fetching public HTTPS proxies...")
    url = "https://free-proxy-list.net/"
    soup = BeautifulSoup(requests.get(url).content, "html.parser")
    proxies = []
    for row in soup.select("table#proxylisttable tbody tr"):
        cols = row.find_all("td")
        if cols[6].text == "yes":
            proxies.append(f"{cols[0].text}:{cols[1].text}")
    with open("proxies.txt", "w") as f:
        for p in proxies:
            f.write(p + "\n")
    print(f"[âœ“] Total proxies saved: {len(proxies)} in proxies.txt\n")


def check_ip(proxy=None):
    try:
        if proxy:
            proxies = {"http": f"http://{proxy}", "https": f"http://{proxy}"}
            r = requests.get("https://api.myip.com", proxies=proxies, timeout=5)
        else:
            r = requests.get("https://api.myip.com", timeout=5)
        print(f"[âœ“] IP Info: {r.json()}")
    except Exception as e:
        print(f"[âœ˜] Proxy Failed ({proxy}):", e)


def scan_link(link):
    print(f"\n[~] Scanning link: {link}")
    try:
        headers = {'User-Agent': 'Mozilla/5.0'}
        r = requests.get(link, headers=headers, timeout=6)
        if r.status_code in [200, 301, 302]:
            print(f"[âœ“] Link is reachable with status: {r.status_code}")
        else:
            print(f"[!] Warning: Unusual status code {r.status_code}")
    except Exception as e:
        print(f"[âœ˜] Error reaching the link: {e}")


def menu():
    while True:
        banner()
        print("""\033[1;36m
[1] âœ… Fetch Fresh Proxies
[2] ğŸŒ Check My IP
[3] ğŸ” Check IP Using First Proxy
[4] ğŸ” Scan Any Link (Safe or Not)
[5] ğŸšª Exit Tool
""")
        ch = input("Select Option â¤ ")
        if ch == '1':
            fetch_proxies()
            input("\nPress Enter to return to menu...")
        elif ch == '2':
            print("\n[âœ“] Your Original IP Info:")
            check_ip()
            input("\nPress Enter to return to menu...")
        elif ch == '3':
            try:
                with open("proxies.txt", "r") as f:
                    first = f.readline().strip()
                    print(f"\n[âœ“] Using Proxy: {first}")
                    check_ip(first)
            except:
                print("[âœ˜] proxies.txt not found. Run option 1 first.")
            input("\nPress Enter to return to menu...")
        elif ch == '4':
            link = input("\nğŸ”— Enter link (include https://): ")
            scan_link(link)
            input("\nPress Enter to return to menu...")
        elif ch == '5':
            print("\n[âœ“] Exiting... Respect karo or karwao âœŒï¸")
            break
        else:
            print("[âœ˜] Invalid Option. Try Again.")
            time.sleep(2)

if __name__ == "__main__":
    menu()
